[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "1 Business Case\nI have the role of a data scientist. I have to look for opportunities to improve the sales. We are interested in\n\nSales by year\nSales by year and product family\n\nHere you can see the given example including the plots.\n\n# Data Science at TUHH ------------------------------------------------------\n# SALES ANALYSIS ----\n\n# 1.0 Load libraries ----\nlibrary(\"tidyverse\")\n\n# 2.0 Importing Files ----\nbikes <- readxl::read_excel(\"../../bikes/01_raw_data/bikes.xlsx\")\nbikeshops <- readxl::read_excel(\"../../bikes/01_raw_data/bikeshops.xlsx\")\norderlines <- readxl::read_excel(\"../../bikes/01_raw_data/orderlines.xlsx\")\n\n#> New names:\n#> • `` -> `...1`\n\n# 3.0 Examining Data ----\n# print(bikes)\n\n# 4.0 Joining Data ----\nbike_orderlines_joined <- orderlines %>%\n  left_join(bikes, by = c(\"product.id\" = \"bike.id\")) %>%\n  left_join(bikeshops, by = c(\"customer.id\" = \"bikeshop.id\"))\n#print(bike_orderlines_joined$category)\n# 5.0 Wrangling Data ----\nbike_orderlines_wrangled <- bike_orderlines_joined %>%\n  separate(col    = category,\n           into   = c(\"category.1\", \"category.2\", \"category.3\"),\n           sep    = \" - \") %>%\n  mutate(total.price = price * quantity) %>%\n  select(-...1, -gender) %>%\n  select(-ends_with(\".id\")) %>%\n  bind_cols(bike_orderlines_joined %>% select(order.id)) %>%\n  select(order.id, contains(\"order\"), contains(\"model\"), contains(\"category\"),\n         price, quantity, total.price,\n         everything()) %>%\n  rename(bikeshop = name) %>%\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\n# 6.0 Business Insights ----\nlibrary(lubridate)\n# 6.1 Sales by Year ----\nsales_by_year <- bike_orderlines_wrangled %>%\n# Step 1 - Manipulate\n  select(order_date, total_price) %>%\n  mutate(year = year(order_date)) %>%\n  group_by(year) %>% \n  summarize(sales = sum(total_price)) %>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n#print(sales_by_year)\n# Step 2 - Visualize\nsales_by_year %>%\n  ggplot(aes(x = year, y = sales)) +\n  geom_col(fill = \"#2DC6D6\") + # Use geom_col for a bar plot\n  geom_label(aes(label = sales_text)) + # Adding labels to the bars\n  geom_smooth(method = \"lm\", se = FALSE) + # Adding a trendline\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title    = \"Revenue by year\",\n    subtitle = \"Upward Trend\",\n    x = \"\", # Override defaults for x and y\n    y = \"Revenue\"\n  )\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# 6.2 Sales by Year and Category 2 ----\n\n  # Step 1 - Manipulate\nsales_by_year_cat_1 <- bike_orderlines_wrangled %>%\n  select(order_date, total_price, category_1) %>%\n  mutate(year = year(order_date)) %>%\n  group_by(year, category_1) %>%\n  summarise(sales = sum(total_price)) %>%\n  ungroup() %>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#> `summarise()` has grouped output by 'year'. You can override using the\n#> `.groups` argument.\n\nsales_by_year_cat_1  \n\n\n\n  \n\n\n# Step 2 - Visualize\nsales_by_year_cat_1 %>%\n  ggplot(aes(x = year, y = sales, fill = category_1)) +\n  geom_col() +\n  facet_wrap(~ category_1) +\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = \"Revenue by year and main category\",\n    subtitle = \"Each product category has an upward trend\",\n    fill = \"Main category\" # Changes the legend name\n  )\n\n\n\n\n\n\n\n# 7.0 Writing Files ----\n\n# 7.1 Excel ----\nlibrary(\"writexl\")\nbike_orderlines_wrangled %>%\n  write_xlsx(\"../../bikes/02_wrangled_data/bike_orderlines.xlsx\")\n\n# 7.2 CSV ----\nbike_orderlines_wrangled %>% \n  write_csv(\"../../bikes/02_wrangled_data/bike_orderlines.csv\")\n# 7.3 RDS ----\nbike_orderlines_wrangled %>% \n  write_rds(\"../../bikes/02_wrangled_data/bike_orderlines.rds\")\n\n\n\n2 Challenge\n\n# 6.3 Sales by location\n\n# Step 1 - Manipulate\nsales_by_location_tbl <- bike_orderlines_wrangled_tbl %>%\n  # Seperate city and state into two separate columns\n  separate(col = location,\n           into = c(\"city\",\"state\"),\n           sep = \", \",\n           convert = T) %>%\n  \n  # Select columns\n  select(state, total_price) %>%\n  \n  # Grouping by year and summarizing sales\n  group_by(state) %>% \n  summarize(sales = sum(total_price)) %>%\n  \n  # Optional: Add a column that turns the numbers into a currency format \n  # (makes it in the plot optically more appealing)\n  # mutate(sales_text = scales::dollar(sales)) <- Works for dollar values\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n \n# Step 2 - Visualize\nsales_by_location_tbl %>%\n  \n  # Setup canvas with the columns year (x-axis) and sales (y-axis)\n  ggplot(aes(x = state, y = sales)) +\n  \n  # Geometries\n  geom_col(fill = \"#2DC6D6\") + # Use geom_col for a bar plot\n  geom_label(aes(label = sales_text)) + # Adding labels to the bars\n  geom_smooth(method = \"lm\", se = FALSE) + # Adding a trendline\n  \n  # Formatting\n  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. \n  # Again, we have to adjust it for euro values\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title    = \"Revenue by location\",\n    subtitle = \"Upward Trend\",\n    x = \"\", # Override defaults for x and y\n    y = \"Revenue\"\n  ) +\n\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# 6.4 Sales by location and year\n# Step 1 - Manipulate\nsales_by_location_and_year_tbl <- bike_orderlines_wrangled_tbl %>%\n  # Seperate city and state into two separate columns\n  separate(col = location,\n           into = c(\"city\",\"state\"),\n           sep = \", \",\n           convert = T) %>%\n  \n  # Select columns and add a year\n  select(state, total_price, order_date) %>%\n  mutate(year = year(order_date)) %>%\n  \n  # Group by and summarize year and main catgegory\n  group_by(state, year) %>%\n  summarise(sales = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # Format $ Text\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#> `summarise()` has grouped output by 'state'. You can override using the\n#> `.groups` argument.\n\n# Step 2 - Visualize\nsales_by_location_and_year_tbl %>%\n  \n  # Set up x, y, fill\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  \n  # Geometries\n  geom_col() + # Run up to here to get a stacked bar plot\n  \n  # Facet\n  facet_wrap(~ state) +\n  \n  # Formatting\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = \"Revenue by location and year\",\n    subtitle = \"Each year has an upward trend\",\n    fill = \"Year\" # Changes the legend name\n  ) +\n\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "Data for analysation can be imported in different ways. One way is to read data from csv or excel sheets, another is to import it directly from databases.\n\nlibrary(RSQLite)\ncon <- RSQLite::dbConnect(drv = SQLite(), dbname = \"../../00_data/02_chinook/Chinook_Sqlite.sqlite\") #connect to database\n\nlibrary(DBI) #to print the tables print(dbListTables(con))\n\nlibrary(dplyr) \nprint(tbl(con, \"Album\")) #to examine table from database\n\n#> # Source:   table<Album> [?? x 3]\n#> # Database: sqlite 3.41.2 [D:\\Git\\ss23-bdsb-juliusace9000\\00_data\\02_chinook\\Chinook_Sqlite.sqlite]\n#>    AlbumId Title                                 ArtistId\n#>      <int> <chr>                                    <int>\n#>  1       1 For Those About To Rock We Salute You        1\n#>  2       2 Balls to the Wall                            2\n#>  3       3 Restless and Wild                            2\n#>  4       4 Let There Be Rock                            1\n#>  5       5 Big Ones                                     3\n#>  6       6 Jagged Little Pill                           4\n#>  7       7 Facelift                                     5\n#>  8       8 Warner 25 Anos                               6\n#>  9       9 Plays Metallica By Four Cellos               7\n#> 10      10 Audioslave                                   8\n#> # i more rows\n\nalbum_tbl <- tbl(con, \"Album\") %>% collect() #pull data in local memory\n\ndbDisconnect(con) #disconnect database"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#and-another-example-with-the-imdb-movie-database",
    "href": "content/01_journal/02_data_acquisition.html#and-another-example-with-the-imdb-movie-database",
    "title": "Data Acquisition",
    "section": "3.1 And another example with the imdb movie database",
    "text": "3.1 And another example with the imdb movie database\n\nurl  <- \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\"\nhtml <- url %>% \n  read_html()\n\nrank <-  html %>% \n  html_nodes(css = \".titleColumn\") %>% \n  html_text() %>% \n  # Extrag all digits between \" \" and \".\\n\" The \"\\\" have to be escaped\n  # You can use Look ahead \"<=\" and Look behind \"?=\" for this\n  stringr::str_extract(\"(?<= )[0-9]*(?=\\\\.\\\\n)\")%>% \n  # Make all values numeric\n  as.numeric()\ntitle <- html %>% \n  html_nodes(\".titleColumn > a\") %>% \n  html_text()\nyear <- html %>% \n  html_nodes(\".titleColumn .secondaryInfo\") %>%\n  html_text() %>% \n  # Extract numbers\n  stringr::str_extract(pattern = \"[0-9]+\") %>% \n  as.numeric()\npeople <- html %>% \n  html_nodes(\".titleColumn > a\") %>% \n  html_attr(\"title\")\nrating <- html %>% \n  html_nodes(css = \".imdbRating > strong\") %>% \n  html_text() %>% \n  as.numeric()\nnum_ratings <- html %>% \n  html_nodes(css = \".imdbRating > strong\") %>% \n  html_attr('title') %>% \n  # Extract the numbers and remove the comma to make it numeric values\n  stringr::str_extract(\"(?<=based on ).*(?=\\ user ratings)\" ) %>% \n  stringr::str_replace_all(pattern = \",\", replacement = \"\") %>% \n  as.numeric()\nimdb_tbl <- tibble(rank, title, year, people, rating, num_ratings)\nprint(imdb_tbl)\n\n#> # A tibble: 250 x 6\n#>     rank title                                    year people rating num_ratings\n#>    <dbl> <chr>                                   <dbl> <chr>   <dbl>       <dbl>\n#>  1     1 Die Verurteilten                         1994 Frank~    9.2     2732526\n#>  2     2 Der Pate                                 1972 Franc~    9.2     1899988\n#>  3     3 The Dark Knight                          2008 Chris~    9       2705719\n#>  4     4 Der Pate 2                               1974 Franc~    9       1295423\n#>  5     5 Die zwölf Geschworenen                   1957 Sidne~    9        808554\n#>  6     6 Schindlers Liste                         1993 Steve~    8.9     1379651\n#>  7     7 Der Herr der Ringe: Die Rückkehr des K~  2003 Peter~    8.9     1879735\n#>  8     8 Pulp Fiction                             1994 Quent~    8.8     2099767\n#>  9     9 Der Herr der Ringe: Die Gefährten        2001 Peter~    8.8     1908686\n#> 10    10 Zwei glorreiche Halunken                 1966 Sergi~    8.8      774414\n#> # i 240 more rows"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#functional-programming",
    "href": "content/01_journal/02_data_acquisition.html#functional-programming",
    "title": "Data Acquisition",
    "section": "3.2 Functional Programming",
    "text": "3.2 Functional Programming\nfor (variable in vector) {\n    \n}\n# Example: For Loop\nnumbers <- c(1:5)\nfor (i in numbers) {\n   print(i)\n}\nwould be written as\nnumbers_list <- map(numbers, print)\n\nExample\n\nbike_data_lst <- fromJSON(\"../../00_data/bike_data.json\")\nbike_data_lst %>%\n  purrr::pluck(\"productDetail\", \"variationAttributes\", \"values\", 1, \"displayValue\") %>%\n  print()\n\n#> [1] \"Stealth\"     \"aero silver\"\n\n\n#Business Case not working."
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#section",
    "href": "content/01_journal/02_data_acquisition.html#section",
    "title": "Data Acquisition",
    "section": "4.1 1",
    "text": "4.1 1\nThe weather for a city in the north of Germany was collected for the past 7 days, including the sunrise, sunset, weathercode and the rain.\n\nresp <- GET(url = \"https://api.open-meteo.com/v1/forecast?latitude=53.6751500&longitude=10.2259300&daily=weathercode,sunrise,sunset,rain_sum&past_days=7&forecast_days=1&timezone=Europe%2FLondon\",\n            add_headers(('accept'= 'application/json')))\nhtml <- content(resp)\nprint(html)\n\n#> $latitude\n#> [1] 53.68\n#> \n#> $longitude\n#> [1] 10.22\n#> \n#> $generationtime_ms\n#> [1] 0.4650354\n#> \n#> $utc_offset_seconds\n#> [1] 3600\n#> \n#> $timezone\n#> [1] \"Europe/London\"\n#> \n#> $timezone_abbreviation\n#> [1] \"BST\"\n#> \n#> $elevation\n#> [1] 46\n#> \n#> $daily_units\n#> $daily_units$time\n#> [1] \"iso8601\"\n#> \n#> $daily_units$weathercode\n#> [1] \"wmo code\"\n#> \n#> $daily_units$sunrise\n#> [1] \"iso8601\"\n#> \n#> $daily_units$sunset\n#> [1] \"iso8601\"\n#> \n#> $daily_units$rain_sum\n#> [1] \"mm\"\n#> \n#> \n#> $daily\n#> $daily$time\n#> $daily$time[[1]]\n#> [1] \"2023-04-22\"\n#> \n#> $daily$time[[2]]\n#> [1] \"2023-04-23\"\n#> \n#> $daily$time[[3]]\n#> [1] \"2023-04-24\"\n#> \n#> $daily$time[[4]]\n#> [1] \"2023-04-25\"\n#> \n#> $daily$time[[5]]\n#> [1] \"2023-04-26\"\n#> \n#> $daily$time[[6]]\n#> [1] \"2023-04-27\"\n#> \n#> $daily$time[[7]]\n#> [1] \"2023-04-28\"\n#> \n#> $daily$time[[8]]\n#> [1] \"2023-04-29\"\n#> \n#> \n#> $daily$weathercode\n#> $daily$weathercode[[1]]\n#> [1] 61\n#> \n#> $daily$weathercode[[2]]\n#> [1] 80\n#> \n#> $daily$weathercode[[3]]\n#> [1] 80\n#> \n#> $daily$weathercode[[4]]\n#> [1] 61\n#> \n#> $daily$weathercode[[5]]\n#> [1] 61\n#> \n#> $daily$weathercode[[6]]\n#> [1] 61\n#> \n#> $daily$weathercode[[7]]\n#> [1] 63\n#> \n#> $daily$weathercode[[8]]\n#> [1] 80\n#> \n#> \n#> $daily$sunrise\n#> $daily$sunrise[[1]]\n#> [1] \"2023-04-22T05:01\"\n#> \n#> $daily$sunrise[[2]]\n#> [1] \"2023-04-23T04:59\"\n#> \n#> $daily$sunrise[[3]]\n#> [1] \"2023-04-24T04:56\"\n#> \n#> $daily$sunrise[[4]]\n#> [1] \"2023-04-25T04:54\"\n#> \n#> $daily$sunrise[[5]]\n#> [1] \"2023-04-26T04:52\"\n#> \n#> $daily$sunrise[[6]]\n#> [1] \"2023-04-27T04:50\"\n#> \n#> $daily$sunrise[[7]]\n#> [1] \"2023-04-28T04:48\"\n#> \n#> $daily$sunrise[[8]]\n#> [1] \"2023-04-29T04:46\"\n#> \n#> \n#> $daily$sunset\n#> $daily$sunset[[1]]\n#> [1] \"2023-04-22T19:33\"\n#> \n#> $daily$sunset[[2]]\n#> [1] \"2023-04-23T19:35\"\n#> \n#> $daily$sunset[[3]]\n#> [1] \"2023-04-24T19:37\"\n#> \n#> $daily$sunset[[4]]\n#> [1] \"2023-04-25T19:39\"\n#> \n#> $daily$sunset[[5]]\n#> [1] \"2023-04-26T19:41\"\n#> \n#> $daily$sunset[[6]]\n#> [1] \"2023-04-27T19:43\"\n#> \n#> $daily$sunset[[7]]\n#> [1] \"2023-04-28T19:45\"\n#> \n#> $daily$sunset[[8]]\n#> [1] \"2023-04-29T19:46\"\n#> \n#> \n#> $daily$rain_sum\n#> $daily$rain_sum[[1]]\n#> [1] 0.1\n#> \n#> $daily$rain_sum[[2]]\n#> [1] 3\n#> \n#> $daily$rain_sum[[3]]\n#> [1] 4.1\n#> \n#> $daily$rain_sum[[4]]\n#> [1] 0.9\n#> \n#> $daily$rain_sum[[5]]\n#> [1] 0.1\n#> \n#> $daily$rain_sum[[6]]\n#> [1] 0.1\n#> \n#> $daily$rain_sum[[7]]\n#> [1] 11\n#> \n#> $daily$rain_sum[[8]]\n#> [1] 0.6\n\nweather_tbl <- tibble(html[[\"daily\"]][[\"time\"]], html[[\"daily\"]][[\"weathercode\"]], html[[\"daily\"]][[\"sunrise\"]], html[[\"daily\"]][[\"sunset\"]], html[[\"daily\"]][[\"rain_sum\"]])\nweather_tbl %>% data.frame %>% print()\n\n#>   html...daily......time... html...daily......weathercode...\n#> 1                2023-04-22                               61\n#> 2                2023-04-23                               80\n#> 3                2023-04-24                               80\n#> 4                2023-04-25                               61\n#> 5                2023-04-26                               61\n#> 6                2023-04-27                               61\n#> 7                2023-04-28                               63\n#> 8                2023-04-29                               80\n#>   html...daily......sunrise... html...daily......sunset...\n#> 1             2023-04-22T05:01            2023-04-22T19:33\n#> 2             2023-04-23T04:59            2023-04-23T19:35\n#> 3             2023-04-24T04:56            2023-04-24T19:37\n#> 4             2023-04-25T04:54            2023-04-25T19:39\n#> 5             2023-04-26T04:52            2023-04-26T19:41\n#> 6             2023-04-27T04:50            2023-04-27T19:43\n#> 7             2023-04-28T04:48            2023-04-28T19:45\n#> 8             2023-04-29T04:46            2023-04-29T19:46\n#>   html...daily......rain_sum...\n#> 1                           0.1\n#> 2                             3\n#> 3                           4.1\n#> 4                           0.9\n#> 5                           0.1\n#> 6                           0.1\n#> 7                            11\n#> 8                           0.6"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#section-1",
    "href": "content/01_journal/02_data_acquisition.html#section-1",
    "title": "Data Acquisition",
    "section": "4.2 2",
    "text": "4.2 2\nWe scraped the electric mountainbike overview from radon bikes with the model names and the prices.\n\n# Challenge 2\nlibrary(tidyverse)\n\n#> -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\n#> v forcats   1.0.0     v readr     2.1.4\n#> v ggplot2   3.4.2     v tibble    3.2.1\n#> v lubridate 1.9.2     v tidyr     1.3.0\n#> v purrr     1.0.1     \n#> -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n#> x dplyr::filter()         masks stats::filter()\n#> x purrr::flatten()        masks jsonlite::flatten()\n#> x readr::guess_encoding() masks rvest::guess_encoding()\n#> x dplyr::lag()            masks stats::lag()\n#> i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(rvest)\nlibrary(xopen)\nlibrary(jsonlite)\nlibrary(glue)\nlibrary(stringi)\n\n\nurl <- \"https://www.radon-bikes.de/e-bike/mountainbike/\"\n\n# People that worked on \"The Dark Knight\"\nbike_names <- url %>% \n  read_html() %>% \n  html_nodes(\".bikeTitle > h4\") %>%\n  html_text() \n\nbike_prices <- url %>% \n  read_html() %>% \n  html_nodes(\".info > div > div > span\") %>%\n  html_text()\nbike_prices <- bike_prices[seq(1,length(bike_prices),2)]\n\nbikes_tbl <- tibble(bike_names, bike_prices)\nbikes_tbl %>% data.frame %>% print()\n\n#>          bike_names bike_prices\n#> 1         RENDER AL        3999\n#> 2            RENDER        4999\n#> 3              DEFT        4799\n#> 4    JEALOUS HYBRID        2499\n#> 5 ZR TEAM HYBRID CX        1799\n#> 6 ZR LADY HYBRID CX        2499"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "I first attempted to replicate both the example and business case, which can be found in the DATA_WRANGLING.R and DATA_WRANGLING_BUSINESS_CASE.R files. After completing this task, I began working on the challenge with a reduced dataset, due to limitations with my hardware.\n\nlibrary(tidyverse)\n\n#> -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\n#> v dplyr     1.1.2     v readr     2.1.4\n#> v forcats   1.0.0     v stringr   1.5.0\n#> v ggplot2   3.4.2     v tibble    3.2.1\n#> v lubridate 1.9.2     v tidyr     1.3.0\n#> v purrr     1.0.1     \n#> -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n#> x dplyr::filter() masks stats::filter()\n#> x dplyr::lag()    masks stats::lag()\n#> i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(data.table)\n\n#> \n#> Attaching package: 'data.table'\n#> \n#> The following objects are masked from 'package:lubridate':\n#> \n#>     hour, isoweek, mday, minute, month, quarter, second, wday, week,\n#>     yday, year\n#> \n#> The following objects are masked from 'package:dplyr':\n#> \n#>     between, first, last\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     transpose\n\nlibrary(dplyr)\nlibrary(vroom)\n\n#> \n#> Attaching package: 'vroom'\n#> \n#> The following objects are masked from 'package:readr':\n#> \n#>     as.col_spec, col_character, col_date, col_datetime, col_double,\n#>     col_factor, col_guess, col_integer, col_logical, col_number,\n#>     col_skip, col_time, cols, cols_condense, cols_only, date_names,\n#>     date_names_lang, date_names_langs, default_locale, fwf_cols,\n#>     fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n#>     problems, spec\n\n## Data Loading ##\n# Using the reduced data set\n\n# loading patent.tsv file\ncol_types_patent <- list(\n  id = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  num_claims = col_double()\n)\npatent_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types_patent,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\npatent_tbl <- rename(patent_tbl,patent_id = id) # Rename id to patent_id to make merging easier\n\nI followed a similar process for loading the assignee.tsv, patent_assignee.tsv, and uspc.tsv files as I did for the patent.tsv file. To determine the appropriate column names and data types for each file, I reviewed the file contents and analyzed the variable types present in each column.\n\n# loading assignee.tsv file\ncol_types_assignee <- list(\n  id = col_character(),\n  type = col_integer(),\n  organization = col_character()\n)\nassignee_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types_assignee,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\nassignee_tbl <- rename(assignee_tbl,assignee_id = id) # Rename id to assignee_id to make merging easier\n\n# loading patent_assignee.tsv file\ncol_types_patent_assignee <- list(\n  patent_id = col_character(),\n  assignee_id = col_character()\n)\npatent_assignee_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/patent_assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types_patent_assignee,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# loading uspc.tsv file\ncol_types_uspc <- list(\n  patent_id = col_character(),\n  mainclass_id = col_character(),\n  sequence = col_integer()\n)\nuspc_tbl <- vroom(\n  file       = \"../../Patent_data_reduced/uspc.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types_uspc,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n\n1 Patent Dominance\nThe following steps were performed for the patent dominance task.\n\n# Convert patent_assignee_tbl to data.table and group it's entries by assignee_id. Then the number of elements per group is stored in a column patents.\npatent_dominance_dt <- as.data.table(patent_assignee_tbl)[,.(patents = .N),by = assignee_id]\n# Combine patent_activity_dt with assignee_tbl by patent_id to combine assignee info with company-name and -type info.\npatent_dominance_dt <- as.data.table(merge(as_tibble(patent_dominance_dt),assignee_tbl,by=\"assignee_id\")) %>%\n                                    .[type == 2] %>% # Then the data table can be filtered by only allowing US Companies or Corporations\n                                    .[order(-patents),patents,organization] # Afterwards the list is sorted by the number of patents.\n                                                                            # Only the patents and organization name column is kept for better looking output.\nprint(\"What US company / corporation has the most patents?\")\n\n#> [1] \"What US company / corporation has the most patents?\"\n\nprint(patent_dominance_dt[1]) # Take the first element of the ordered list.\n\n#>                                   organization patents\n#> 1: International Business Machines Corporation    7547\n\nprint(\"List the 10 US companies with the most assigned/granted patents.\")\n\n#> [1] \"List the 10 US companies with the most assigned/granted patents.\"\n\nprint(patent_dominance_dt[1:10]) # Take the first 10 elements of the ordered list.\n\n#>                                    organization patents\n#>  1: International Business Machines Corporation    7547\n#>  2:                       Microsoft Corporation    3165\n#>  3:                                 Google Inc.    2668\n#>  4:                       QUALCOMM Incorporated    2597\n#>  5:                                  Apple Inc.    2201\n#>  6:                    General Electric Company    1873\n#>  7:   Hewlett-Packard Development Company, L.P.    1638\n#>  8:          AT&T INTELLECTUAL PROPERTY I, L.P.    1625\n#>  9:                           Intel Corporation    1616\n#> 10:         GM Global Technology Operations LLC    1533\n\n\n\n\n2 Recent Patent Activity\nSimilarly I performed following steps (some similar to patent dominance) to find the top companies by patent activity in august of 2014:\n\n# Take patent_tbl and separate into year, month and day and convert to data.table.\npatent_activity_dt <- patent_tbl %>% separate(col = date,into = c(\"year\",\"month\",\"day\"),sep = \"-\",convert = T) %>%\n                                 as.data.table() %>% .[year == 2014 & month == 8] # Then filter by august (8) 2014.\n# Combine patent_activity_dt with patent_assignee_tbl by patent_id to combine patent info with assignee info..\npatent_activity_dt <- as.data.table(merge(as_tibble(patent_activity_dt),patent_assignee_tbl,by=\"patent_id\")) %>%\n                                   .[,.(patents = .N),by = assignee_id] # Group and sum up by assignee_id.\n# Combine patent_activity_dt with assignee_tbl by patent_id to combine assignee info with company-name and -type info.\npatent_activity_dt <- as.data.table(merge(as_tibble(patent_activity_dt),assignee_tbl,by=\"assignee_id\")) %>%\n                                    .[order(-patents),.(organization,type,patents)] # Order by number of patents and discard assignee_id.\n\nprint(\"What US company had the most patents granted in August 2014?\")\n\n#> [1] \"What US company had the most patents granted in August 2014?\"\n\nprint(patent_activity_dt[type == 2][1]) # Filter by US Company or Corporation and take the first element of the ordered list.\n\n#>                                   organization type patents\n#> 1: International Business Machines Corporation    2     718\n\nprint(\"List the top 10 companies with the most new granted patents for August 2014.\")\n\n#> [1] \"List the top 10 companies with the most new granted patents for August 2014.\"\n\nprint(patent_activity_dt[1:10]) # Take the first 10 elements of the ordered list.\n\n#>                                    organization type patents\n#>  1: International Business Machines Corporation    2     718\n#>  2:               Samsung Electronics Co., Ltd.    3     524\n#>  3:                      Canon Kabushiki Kaisha    3     361\n#>  4:                       Microsoft Corporation    2     337\n#>  5:                            Sony Corporation    3     269\n#>  6:                                 Google Inc.    2     240\n#>  7:                       QUALCOMM Incorporated    2     223\n#>  8:                                  Apple Inc.    2     222\n#>  9:                    Kabushiki Kaisha Toshiba    3     213\n#> 10:                         LG Electronics Inc.    3     211\n\n\n\n\n3 Innovation In Tech\nSimilarly I performed these steps (some similar to patent dominance and recent patent activity) to find the top main classes:\n\n# For most innovative tech sensor group and sum the uspc_tbl by mainclass_id.\nmost_innovative_tech_sectors <- as.data.table(uspc_tbl)[,.(patents = .N),by = mainclass_id] %>%\n                                            .[order(-patents),patents,mainclass_id] # Then order the list by descending patents.\n# Retrieve the assignee_ids of the 10 companies that have the most patents and only keep the assignee_ids of those.\ntop_USPTO_main_classes <- as.data.table(patent_assignee_tbl)[,.(patents = .N),by = assignee_id][1:10][,assignee_id]\n# Search through the patent_assignee_tbl again and only keep those patents that come from one of those 10 companies.\ntop_USPTO_main_classes <- as.data.table(patent_assignee_tbl)[assignee_id %in% top_USPTO_main_classes]\n# With the list of patents combine it by the patent_id with the uspc_tbl.\ntop_USPTO_main_classes <- as.data.table(merge(as_tibble(top_USPTO_main_classes),uspc_tbl,by=\"patent_id\")) %>%\n                                        .[,.(patents = .N),by = mainclass_id] %>% # Group and sum up by mainclass_id.\n                                        .[order(-patents),patents,mainclass_id] # Then order the list by descending patents.\n\nprint(\"What is the most innovative tech sector?\")\n\n#> [1] \"What is the most innovative tech sector?\"\n\nprint(most_innovative_tech_sectors[1]) # Take the first element of the ordered list.\n\n#>    mainclass_id patents\n#> 1:          257   40526\n\nprint(\"For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?\")\n\n#> [1] \"For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?\"\n\nprint(top_USPTO_main_classes[1:10]) # Take the first 10 elements of the ordered list.\n\n#>     mainclass_id patents\n#>  1:          370    1672\n#>  2:          455    1640\n#>  3:          375     743\n#>  4:          257     701\n#>  5:          166     699\n#>  6:          709     417\n#>  7:          244     344\n#>  8:          438     324\n#>  9:          398     323\n#> 10:          507     179"
  },
  {
    "objectID": "content/01_journal/04_challenge.html",
    "href": "content/01_journal/04_challenge.html",
    "title": "Data Visualization",
    "section": "",
    "text": "1 Challenge 4.1\n\nlibrary(data.table)\nlibrary(tidyverse) # loads ggplot2\nlibrary(lubridate)\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(scales)\nlibrary(maps)\n\n#> \n#> Attaching package: 'maps'\n\n\n#> The following object is masked from 'package:purrr':\n#> \n#>     map\n\noptions(repr.plot.width=50, repr.plot.height=3)\n\n# Challenge 1\n\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 306185 Columns: 67\n\n\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncovid_data_graph_tbl <- covid_data_tbl %>% # Read the covid data\n  filter(location == \"Europe\" | location == \"Germany\" | location == \"United Kingdom\" | location == \"France\" | location == \"Spain\" | location == \"United States\") %>% # Filter only the locations specified in the task\n  select(date,total_cases,location) %>% # Only date, total_cases and location are needed\n  filter(!is.na(total_cases)) %>% # Remove those dates where the total_cases number is not a number\n  filter(date < '2022-04-20') # Plot in task stops in may of 2022, so this data stops there as well\n\ncovid_data_dt <- as.data.table(covid_data_graph_tbl) # Convert tibble to data.frame\n\nlast_date_europe <- covid_data_dt[location == \"Europe\"][order(-date)][1]$date\nlast_date_USA <- covid_data_dt[location == \"United States\"][order(-date)][1]$date\n\naddMillions <- function(x, ...) #<== function will add \" %\" to any number, and allows for any additional formatting through \"format\".\n    format(paste0(x/(1e+06), \" M\"), ...)\n\ncovid_data_dt %>% ggplot(aes(x=date,y=total_cases),palette=\"Dark2\") + # plot total_cases over time\n  geom_line(aes(colour=location)) + # each location gets its own line\n  theme(legend.position = \"bottom\") + # position legend at the bottom\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%B '%y\") + # Change the x axis to a date axis with montly intervals and \"month 'year\" labels\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate the x-axis labels by 45 degrees so they don't collide with each other\n  scale_y_continuous(breaks = seq(0, 200000000, by = 50000000), labels = addMillions) + \n  labs( title = \"COVID-19 confirmed cases worldwide\", # Set plot title.\n        subtitle = \"As of 19/04/2022\", # Set plot subtitle.\n        y = \"Cumulative Cases\", # Set plot y-axis label.\n        colour=\"Continent / Country\") + # Set location/country legend title.\n  theme(axis.title.x=element_blank(), # Remove x axis label \n        text = element_text(size=10)) + # Increase text size\n\n  geom_label( # Display geom_label for europe and united states last data point\n    data=covid_data_dt %>% filter((location == \"Europe\" & date == last_date_europe) | (location == \"United States\" & date == last_date_USA)),\n    aes(label=total_cases),hjust=1,vjust=0.4\n  )\n\n\n\n\n\n\n\n\n#Challenge 4.2\n\n# Challenge 2\n\n# Get Case-Fatality rate (deaths/cases)\ncovid_data_graph_tbl <- covid_data_tbl %>% # Read the covid data.\n  filter(!is.na(total_cases) & !is.na(total_deaths) & !is.na(total_deaths_per_million)) %>% # Remove those dates where the total_cases number is not a number.\n  group_by(location) %>% summarise(total_cases = sum(total_cases),total_deaths = sum(total_deaths),total_deaths_per_million = sum(total_deaths_per_million)) %>% # Group by location (country) and sum up total_cases and total_deaths over all dates.\n  mutate(fatality_rate = (total_deaths/total_cases)) %>% # Add fatality_rate column to the tibble.\n                                                         # Can be exchanged for total_deaths_per_million to visualize mortality rate.\n  select(fatality_rate,location) %>%  # Only maintain fatality_rate and location\n  mutate(location = case_when( # Replace non matching location names\n    \n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n    \n  )) %>%\n  distinct()\n\ntotal_deaths_worldwide <- covid_data_tbl %>% filter(!is.na(total_deaths)) %>% group_by(location) %>% filter(row_number()==n()) %>% summarise(total_deaths) %>%\n                                        ungroup() %>% summarise(total_deaths = sum(total_deaths))\n\nlibrary(RColorBrewer)\nlibrary(maptools)\n\n#> Loading required package: sp\n\n\n#> Checking rgeos availability: FALSE\n#> Please note that 'maptools' will be retired by the end of 2023,\n#> plan transition at your earliest convenience;\n#> some functionality will be moved to 'sp'.\n#>      Note: when rgeos is not available, polygon geometry     computations in maptools depend on gpclib,\n#>      which has a restricted licence. It is disabled by default;\n#>      to enable gpclib, type gpclibPermit()\n\ncolour_breaks <- c(10, 20, 30)\ncolours <- c(\"darkblue\", \"lightblue\", \"yellow\")\n\nworld <- map_data(\"world\")\nggplot(covid_data_graph_tbl) + \n  geom_map(dat=world, map=world, \n           aes(map_id=region), fill=\"white\", color=\"black\") + \n  geom_map(map=world, \n           aes(map_id=location, fill=fatality_rate), color=\"black\") + \n  expand_limits(x = world$long, y = world$lat) +\n  labs( title = \"Confirmed COVID-19 fatality rate.\", # Set plot title.\n        subtitle = paste0(\"Around \",round(total_deaths_worldwide / 1e6, 1),\" Million confirmed COVID-19 deaths worldwide.\"), # Set plot subtitle.\n        caption = paste0(\"Date:\",format(Sys.Date(), format=\"%d/%m/%Y\")), # Set plot caption.\n        fill = \"Fatality rate\") + # Set plot legend caption.\n  theme(axis.title.x=element_blank(), # Remove x axis label. \n        axis.title.y=element_blank(), # Remove y axis label.\n        axis.ticks = element_blank(), # Remove axis ticks.\n        axis.text.x = element_blank(), # Remove x axis texts.\n        axis.text.y = element_blank(), # Remove y axis texts.\n        )"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "library(\"scales\")\n\nlibrary(\"tidyverse\") # loads ggplot2\n\n#> -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\n#> v dplyr     1.1.2     v readr     2.1.4\n#> v forcats   1.0.0     v stringr   1.5.0\n#> v ggplot2   3.4.2     v tibble    3.2.1\n#> v lubridate 1.9.2     v tidyr     1.3.0\n#> v purrr     1.0.1     \n#> -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n#> x readr::col_factor() masks scales::col_factor()\n#> x purrr::discard()    masks scales::discard()\n#> x dplyr::filter()     masks stats::filter()\n#> x dplyr::lag()        masks stats::lag()\n#> i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(\"lubridate\")\n\nbike_orderlines_tbl <- read_rds(\"../../bikes/02_wrangled_data/bike_orderlines.rds\")\n\n# 1.0 Anatomy of a ggplot ----\n\n# 1.1 How ggplot works ----\n\n# Step 1: Format data ----\n\nsales_by_year_tbl <- bike_orderlines_tbl %>%\n  \n  # Selecting columns to focus on and adding a year column\n  select(order_date, total_price) %>%\n  mutate(year = year(order_date)) %>%\n  \n  # Grouping by year, and summarizing sales\n  group_by(year) %>%\n  summarize(sales = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # € Format Text\n  mutate(sales_text = scales::dollar(sales, \n                                     big.mark     = \".\", \n                                     decimal.mark = \",\", \n                                     prefix       = \"\", \n                                     suffix       = \" €\"))\n\nsales_by_year_tbl\n\n\n\n  \n\n\n# Step 2: Plot ----\nsales_by_year_tbl %>%\n  \n  # Canvas\n  ggplot(aes(x = year, y = sales, color = sales))\n\n\n\n\n\n\n\n# Without piping \nggplot(data = sales_by_year_tbl, \n       aes(x     = year, \n           y     = sales, \n           color = sales))\n\n\n\n\n\n\n\nsales_by_year_tbl %>%\n  \n  # Canvas\n  ggplot(aes(x = year, y = sales, color = sales)) +\n  \n  # Geometries \n  geom_line(size = 1) +\n  geom_point(size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE) -> base_plot\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> i Please use `linewidth` instead.\n\nbase_plot +\n  \n  # not what you want because 2 is not a variable\n  geom_point(aes(size = 2),\n             \n             # this is fine -- turns all points red\n             color = \"red\")\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n#> Warning: The following aesthetics were dropped during statistical transformation: colour\n#> i This can happen when ggplot fails to infer the correct grouping structure in\n#>   the data.\n#> i Did you forget to specify a `group` aesthetic or to convert a numerical\n#>   variable into a factor?\n\n\n\n\n\n\n\n\n# Data Manipulation\norder_value_tbl <- bike_orderlines_tbl %>%\n  \n  select(order_id, order_line, total_price, quantity) %>%\n  \n  group_by(order_id) %>%\n  summarize(\n    total_quantity = sum(quantity),\n    total_price    = sum(total_price)\n  ) %>%\n  ungroup()\n\n# Scatter Plot\norder_value_tbl %>%\n  \n  ggplot(aes(x = total_quantity, y = total_price)) +\n  \n  geom_point(alpha = 0.5, size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Data Manipulation\nrevenue_by_month_tbl <- bike_orderlines_tbl %>%\n  \n  select(order_date, total_price) %>%\n  \n  mutate(year_month = floor_date(order_date, \"months\") %>% ymd()) %>%\n  \n  group_by(year_month) %>%\n  summarize(revenue = sum(total_price)) %>%\n  ungroup()\n\n# Line Plot\nrevenue_by_month_tbl %>%\n  \n  ggplot(aes(year_month, revenue)) +\n  \n  geom_line(size = 0.5, linetype = 1) +\n  geom_smooth(method = \"loess\", span = 0.2)\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Data Manipulation\nrevenue_by_category_2_tbl <- bike_orderlines_tbl %>%\n  \n  select(category_2, total_price) %>%\n  \n  group_by(category_2) %>%\n  summarize(revenue = sum(total_price)) %>%\n  ungroup()\n\n# Bar Plot\nrevenue_by_category_2_tbl %>%\n  \n  mutate(category_2 = category_2 %>% as_factor() %>% fct_reorder(revenue)) %>%\n  \n  ggplot(aes(category_2, revenue)) +\n  \n  geom_col(fill = \"#2c3e50\") + \n  coord_flip()\n\n\n\n\n\n\n\n# Histogram\n\nbike_orderlines_tbl %>%\n  \n  distinct(model, price) %>%\n  \n  ggplot(aes(price)) +\n  \n  geom_histogram(bins = 25, fill = \"blue\", color = \"white\")\n\n\n\n\n\n\n\n# Histogram\nbike_orderlines_tbl %>%\n  \n  distinct(price, model, frame_material) %>%\n  \n  ggplot(aes(price, fill = frame_material)) +\n  \n  geom_histogram() +\n  \n  facet_wrap(~ frame_material, ncol = 1)\n\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n# Density\nbike_orderlines_tbl %>%\n  \n  distinct(price, model, frame_material) %>%\n  \n  ggplot(aes(price, fill = frame_material)) +\n  \n  geom_density(alpha = 0.5) +\n  # facet_wrap(~ frame_material, ncol = 1) +\n  \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n# Data Manipulation\nunit_price_by_cat_2_tbl <- bike_orderlines_tbl %>%\n  \n  select(category_2, model, price) %>%\n  distinct() %>%\n  \n  mutate(category_2 = as_factor(category_2) %>% fct_reorder(price))\n\n# Box Plot\nunit_price_by_cat_2_tbl %>%\n  \n  ggplot(aes(category_2, price)) +\n  \n  geom_boxplot() +\n  coord_flip()\n\n\n\n\n\n\n\n# Violin Plot & Jitter Plot\n\nunit_price_by_cat_2_tbl %>%\n  \n  ggplot(aes(category_2, price)) +\n  \n  geom_jitter(width = 0.15, color = \"#2c3e50\") +\n  geom_violin(alpha = 0.5) +\n  \n  coord_flip()\n\n#> Warning: Groups with fewer than two data points have been dropped.\n\n\n\n\n\n\n\n\n# Data Manipulation\n\nrevenue_by_year_tbl <- bike_orderlines_tbl %>%\n  \n  select(order_date, total_price) %>%\n  \n  mutate(year = year(order_date)) %>%\n  \n  group_by(year) %>%\n  summarize(revenue = sum(total_price)) %>%\n  ungroup()\n\n# Adding text to bar chart\n# Filtering labels to highlight a point\n\nrevenue_by_year_tbl %>%\n  \n  ggplot(aes(year, revenue)) +\n  \n  geom_col(fill = \"#2c3e50\") +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  \n  geom_text(aes(label =  scales::dollar(revenue, \n                                        scale  = 1e-6, \n                                        prefix = \"\",\n                                        suffix = \"M\")), \n            vjust = 1.5, color = \"white\") +\n  \n  geom_label(label =  \"Major Demand This Year\",\n             vjust = -0.5, \n             size  = 5,\n             fill  = \"#1f78b4\",\n             color = \"white\",\n             fontface = \"italic\",\n             data = revenue_by_year_tbl %>%\n               filter(year %in% c(2019))) + \n  \n  expand_limits(y = 2e7)\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsales_by_year_tbl %>%\n  \n  # Canvas\n  ggplot(aes(x = year, y = sales, color = sales)) +\n  \n  # Geometries \n  geom_line(size = 1) +\n  geom_point(size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  \n  # same as above, with explicit scales\n  scale_x_continuous() +\n  scale_y_continuous() +\n  scale_colour_continuous()\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n#> Warning: The following aesthetics were dropped during statistical transformation: colour\n#> i This can happen when ggplot fails to infer the correct grouping structure in\n#>   the data.\n#> i Did you forget to specify a `group` aesthetic or to convert a numerical\n#>   variable into a factor?\n\n\n\n\n\n\n\n\nsales_by_year_tbl %>%\n  \n  # Canvas\n  ggplot(aes(x = year, y = sales, color = sales)) +\n  \n  # Geometries \n  geom_line(size = 1) +\n  geom_point(size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#d62dc6\") +\n  \n  # Formatting\n  expand_limits(y = 0) +\n  # You can also type \"red\", \"black\" etc. for the colors\n  scale_color_continuous(low    = \"#95E1EA\", high = \"#2097A3\", \n                         labels = scales::dollar_format(scale  = 1/1e6, \n                                                        prefix = \"\", \n                                                        suffix = \"M €\")) +\n  scale_y_continuous(labels = scales::dollar_format(scale  = 1/1e6, \n                                                    prefix = \"\", \n                                                    suffix = \"M €\")) +\n  labs(\n    title = \"Revenue\",\n    subtitle = \"Sales are trending up and to the right!\",\n    x = \"\",\n    y = \"Sales (Millions)\",\n    color = \"Rev (M €)\",\n    caption = \"What's happening?\\nSales numbers showing year-over-year growth.\"\n  )\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nlibrary(ggthemes)\n## DATA PREPARATION\nsales_by_month_2015 <- bike_orderlines_tbl %>%\n  \n  # Selecting columns to focus on and adding a month column\n  select(order_date, total_price) %>%\n  mutate(year  = year(order_date)) %>% \n  mutate(month = month(order_date)) %>%\n  \n  filter(year == \"2015\") %>%\n  \n  # Grouping by month, and summarizing sales\n  group_by(month) %>%\n  summarize(sales = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # $ Format Text\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\",\n                                     decimal.mark    = \",\",\n                                     prefix          = \"\",  \n                                     suffix          = \" €\"))\n\n## PLOTTING\n# Canvas\nsales_by_month_2015 %>% \n  ggplot(aes(x = month, y = sales, color = sales)) +\n  \n  # Geometries \n  geom_line(size = 1) +\n  geom_point(size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  \n  # Formatting\n  expand_limits(y = 0) +\n  scale_color_continuous(low = \"red\", high = \"black\",\n                         labels = scales::dollar_format(scale = 1/1e6, \n                                                        prefix = \"\", \n                                                        suffix = \"M €\")) +\n  scale_x_continuous(breaks = sales_by_month_2015$month, \n                     labels = month(sales_by_month_2015$month, label = T)) +\n  scale_y_continuous(labels = scales::dollar_format(scale = 1/1e6, \n                                                    prefix = \"\", \n                                                    suffix = \"M\")) +\n  labs(\n    title = \"Monthly sales (2015)\",\n    subtitle = \"April is the strongest month!\",\n    x = \"\",\n    y = \"Sales (Millions)\",\n    color = \"Rev (M €)\",\n    caption = \"What's happening?\\nSales numbers are dropping towards the end of the year.\"\n  )  +  \n  theme_economist() +\n  theme(legend.position  = \"right\", \n        legend.direction = \"vertical\",\n        axis.text.x = element_text(angle = 45))\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n#> Warning: The following aesthetics were dropped during statistical transformation: colour\n#> i This can happen when ggplot fails to infer the correct grouping structure in\n#>   the data.\n#> i Did you forget to specify a `group` aesthetic or to convert a numerical\n#>   variable into a factor?\n\n\n\n\n\n\n\n\n# Data Manipulation\n\nsales_by_year_category_1_tbl <- bike_orderlines_tbl %>%\n  select(order_date, category_1, total_price) %>%\n  \n  mutate(order_date = ymd(order_date)) %>%\n  mutate(year = year(order_date)) %>%\n  \n  group_by(category_1, year) %>%\n  summarize(revenue = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # Convert character vectors to factors\n  # Arrange by year and revenue\n  mutate(category_1 = fct_reorder2(category_1, year, revenue))\n\n#> `summarise()` has grouped output by 'category_1'. You can override using the\n#> `.groups` argument.\n\nsales_by_year_category_1_tbl\n\n\n\n  \n\n\n# Uncover the factor levels (just for demonstration)\n# sorted by years and the highest revenues\nsales_by_year_category_1_tbl %>%\n  mutate(category_1_num = as.numeric(category_1)) %>%\n  arrange(category_1_num)\n\n\n\n  \n\n\n# Named Colors. This returns a long list of colors that can be used by name\ncolors()\n\n#>   [1] \"white\"                \"aliceblue\"            \"antiquewhite\"        \n#>   [4] \"antiquewhite1\"        \"antiquewhite2\"        \"antiquewhite3\"       \n#>   [7] \"antiquewhite4\"        \"aquamarine\"           \"aquamarine1\"         \n#>  [10] \"aquamarine2\"          \"aquamarine3\"          \"aquamarine4\"         \n#>  [13] \"azure\"                \"azure1\"               \"azure2\"              \n#>  [16] \"azure3\"               \"azure4\"               \"beige\"               \n#>  [19] \"bisque\"               \"bisque1\"              \"bisque2\"             \n#>  [22] \"bisque3\"              \"bisque4\"              \"black\"               \n#>  [25] \"blanchedalmond\"       \"blue\"                 \"blue1\"               \n#>  [28] \"blue2\"                \"blue3\"                \"blue4\"               \n#>  [31] \"blueviolet\"           \"brown\"                \"brown1\"              \n#>  [34] \"brown2\"               \"brown3\"               \"brown4\"              \n#>  [37] \"burlywood\"            \"burlywood1\"           \"burlywood2\"          \n#>  [40] \"burlywood3\"           \"burlywood4\"           \"cadetblue\"           \n#>  [43] \"cadetblue1\"           \"cadetblue2\"           \"cadetblue3\"          \n#>  [46] \"cadetblue4\"           \"chartreuse\"           \"chartreuse1\"         \n#>  [49] \"chartreuse2\"          \"chartreuse3\"          \"chartreuse4\"         \n#>  [52] \"chocolate\"            \"chocolate1\"           \"chocolate2\"          \n#>  [55] \"chocolate3\"           \"chocolate4\"           \"coral\"               \n#>  [58] \"coral1\"               \"coral2\"               \"coral3\"              \n#>  [61] \"coral4\"               \"cornflowerblue\"       \"cornsilk\"            \n#>  [64] \"cornsilk1\"            \"cornsilk2\"            \"cornsilk3\"           \n#>  [67] \"cornsilk4\"            \"cyan\"                 \"cyan1\"               \n#>  [70] \"cyan2\"                \"cyan3\"                \"cyan4\"               \n#>  [73] \"darkblue\"             \"darkcyan\"             \"darkgoldenrod\"       \n#>  [76] \"darkgoldenrod1\"       \"darkgoldenrod2\"       \"darkgoldenrod3\"      \n#>  [79] \"darkgoldenrod4\"       \"darkgray\"             \"darkgreen\"           \n#>  [82] \"darkgrey\"             \"darkkhaki\"            \"darkmagenta\"         \n#>  [85] \"darkolivegreen\"       \"darkolivegreen1\"      \"darkolivegreen2\"     \n#>  [88] \"darkolivegreen3\"      \"darkolivegreen4\"      \"darkorange\"          \n#>  [91] \"darkorange1\"          \"darkorange2\"          \"darkorange3\"         \n#>  [94] \"darkorange4\"          \"darkorchid\"           \"darkorchid1\"         \n#>  [97] \"darkorchid2\"          \"darkorchid3\"          \"darkorchid4\"         \n#> [100] \"darkred\"              \"darksalmon\"           \"darkseagreen\"        \n#> [103] \"darkseagreen1\"        \"darkseagreen2\"        \"darkseagreen3\"       \n#> [106] \"darkseagreen4\"        \"darkslateblue\"        \"darkslategray\"       \n#> [109] \"darkslategray1\"       \"darkslategray2\"       \"darkslategray3\"      \n#> [112] \"darkslategray4\"       \"darkslategrey\"        \"darkturquoise\"       \n#> [115] \"darkviolet\"           \"deeppink\"             \"deeppink1\"           \n#> [118] \"deeppink2\"            \"deeppink3\"            \"deeppink4\"           \n#> [121] \"deepskyblue\"          \"deepskyblue1\"         \"deepskyblue2\"        \n#> [124] \"deepskyblue3\"         \"deepskyblue4\"         \"dimgray\"             \n#> [127] \"dimgrey\"              \"dodgerblue\"           \"dodgerblue1\"         \n#> [130] \"dodgerblue2\"          \"dodgerblue3\"          \"dodgerblue4\"         \n#> [133] \"firebrick\"            \"firebrick1\"           \"firebrick2\"          \n#> [136] \"firebrick3\"           \"firebrick4\"           \"floralwhite\"         \n#> [139] \"forestgreen\"          \"gainsboro\"            \"ghostwhite\"          \n#> [142] \"gold\"                 \"gold1\"                \"gold2\"               \n#> [145] \"gold3\"                \"gold4\"                \"goldenrod\"           \n#> [148] \"goldenrod1\"           \"goldenrod2\"           \"goldenrod3\"          \n#> [151] \"goldenrod4\"           \"gray\"                 \"gray0\"               \n#> [154] \"gray1\"                \"gray2\"                \"gray3\"               \n#> [157] \"gray4\"                \"gray5\"                \"gray6\"               \n#> [160] \"gray7\"                \"gray8\"                \"gray9\"               \n#> [163] \"gray10\"               \"gray11\"               \"gray12\"              \n#> [166] \"gray13\"               \"gray14\"               \"gray15\"              \n#> [169] \"gray16\"               \"gray17\"               \"gray18\"              \n#> [172] \"gray19\"               \"gray20\"               \"gray21\"              \n#> [175] \"gray22\"               \"gray23\"               \"gray24\"              \n#> [178] \"gray25\"               \"gray26\"               \"gray27\"              \n#> [181] \"gray28\"               \"gray29\"               \"gray30\"              \n#> [184] \"gray31\"               \"gray32\"               \"gray33\"              \n#> [187] \"gray34\"               \"gray35\"               \"gray36\"              \n#> [190] \"gray37\"               \"gray38\"               \"gray39\"              \n#> [193] \"gray40\"               \"gray41\"               \"gray42\"              \n#> [196] \"gray43\"               \"gray44\"               \"gray45\"              \n#> [199] \"gray46\"               \"gray47\"               \"gray48\"              \n#> [202] \"gray49\"               \"gray50\"               \"gray51\"              \n#> [205] \"gray52\"               \"gray53\"               \"gray54\"              \n#> [208] \"gray55\"               \"gray56\"               \"gray57\"              \n#> [211] \"gray58\"               \"gray59\"               \"gray60\"              \n#> [214] \"gray61\"               \"gray62\"               \"gray63\"              \n#> [217] \"gray64\"               \"gray65\"               \"gray66\"              \n#> [220] \"gray67\"               \"gray68\"               \"gray69\"              \n#> [223] \"gray70\"               \"gray71\"               \"gray72\"              \n#> [226] \"gray73\"               \"gray74\"               \"gray75\"              \n#> [229] \"gray76\"               \"gray77\"               \"gray78\"              \n#> [232] \"gray79\"               \"gray80\"               \"gray81\"              \n#> [235] \"gray82\"               \"gray83\"               \"gray84\"              \n#> [238] \"gray85\"               \"gray86\"               \"gray87\"              \n#> [241] \"gray88\"               \"gray89\"               \"gray90\"              \n#> [244] \"gray91\"               \"gray92\"               \"gray93\"              \n#> [247] \"gray94\"               \"gray95\"               \"gray96\"              \n#> [250] \"gray97\"               \"gray98\"               \"gray99\"              \n#> [253] \"gray100\"              \"green\"                \"green1\"              \n#> [256] \"green2\"               \"green3\"               \"green4\"              \n#> [259] \"greenyellow\"          \"grey\"                 \"grey0\"               \n#> [262] \"grey1\"                \"grey2\"                \"grey3\"               \n#> [265] \"grey4\"                \"grey5\"                \"grey6\"               \n#> [268] \"grey7\"                \"grey8\"                \"grey9\"               \n#> [271] \"grey10\"               \"grey11\"               \"grey12\"              \n#> [274] \"grey13\"               \"grey14\"               \"grey15\"              \n#> [277] \"grey16\"               \"grey17\"               \"grey18\"              \n#> [280] \"grey19\"               \"grey20\"               \"grey21\"              \n#> [283] \"grey22\"               \"grey23\"               \"grey24\"              \n#> [286] \"grey25\"               \"grey26\"               \"grey27\"              \n#> [289] \"grey28\"               \"grey29\"               \"grey30\"              \n#> [292] \"grey31\"               \"grey32\"               \"grey33\"              \n#> [295] \"grey34\"               \"grey35\"               \"grey36\"              \n#> [298] \"grey37\"               \"grey38\"               \"grey39\"              \n#> [301] \"grey40\"               \"grey41\"               \"grey42\"              \n#> [304] \"grey43\"               \"grey44\"               \"grey45\"              \n#> [307] \"grey46\"               \"grey47\"               \"grey48\"              \n#> [310] \"grey49\"               \"grey50\"               \"grey51\"              \n#> [313] \"grey52\"               \"grey53\"               \"grey54\"              \n#> [316] \"grey55\"               \"grey56\"               \"grey57\"              \n#> [319] \"grey58\"               \"grey59\"               \"grey60\"              \n#> [322] \"grey61\"               \"grey62\"               \"grey63\"              \n#> [325] \"grey64\"               \"grey65\"               \"grey66\"              \n#> [328] \"grey67\"               \"grey68\"               \"grey69\"              \n#> [331] \"grey70\"               \"grey71\"               \"grey72\"              \n#> [334] \"grey73\"               \"grey74\"               \"grey75\"              \n#> [337] \"grey76\"               \"grey77\"               \"grey78\"              \n#> [340] \"grey79\"               \"grey80\"               \"grey81\"              \n#> [343] \"grey82\"               \"grey83\"               \"grey84\"              \n#> [346] \"grey85\"               \"grey86\"               \"grey87\"              \n#> [349] \"grey88\"               \"grey89\"               \"grey90\"              \n#> [352] \"grey91\"               \"grey92\"               \"grey93\"              \n#> [355] \"grey94\"               \"grey95\"               \"grey96\"              \n#> [358] \"grey97\"               \"grey98\"               \"grey99\"              \n#> [361] \"grey100\"              \"honeydew\"             \"honeydew1\"           \n#> [364] \"honeydew2\"            \"honeydew3\"            \"honeydew4\"           \n#> [367] \"hotpink\"              \"hotpink1\"             \"hotpink2\"            \n#> [370] \"hotpink3\"             \"hotpink4\"             \"indianred\"           \n#> [373] \"indianred1\"           \"indianred2\"           \"indianred3\"          \n#> [376] \"indianred4\"           \"ivory\"                \"ivory1\"              \n#> [379] \"ivory2\"               \"ivory3\"               \"ivory4\"              \n#> [382] \"khaki\"                \"khaki1\"               \"khaki2\"              \n#> [385] \"khaki3\"               \"khaki4\"               \"lavender\"            \n#> [388] \"lavenderblush\"        \"lavenderblush1\"       \"lavenderblush2\"      \n#> [391] \"lavenderblush3\"       \"lavenderblush4\"       \"lawngreen\"           \n#> [394] \"lemonchiffon\"         \"lemonchiffon1\"        \"lemonchiffon2\"       \n#> [397] \"lemonchiffon3\"        \"lemonchiffon4\"        \"lightblue\"           \n#> [400] \"lightblue1\"           \"lightblue2\"           \"lightblue3\"          \n#> [403] \"lightblue4\"           \"lightcoral\"           \"lightcyan\"           \n#> [406] \"lightcyan1\"           \"lightcyan2\"           \"lightcyan3\"          \n#> [409] \"lightcyan4\"           \"lightgoldenrod\"       \"lightgoldenrod1\"     \n#> [412] \"lightgoldenrod2\"      \"lightgoldenrod3\"      \"lightgoldenrod4\"     \n#> [415] \"lightgoldenrodyellow\" \"lightgray\"            \"lightgreen\"          \n#> [418] \"lightgrey\"            \"lightpink\"            \"lightpink1\"          \n#> [421] \"lightpink2\"           \"lightpink3\"           \"lightpink4\"          \n#> [424] \"lightsalmon\"          \"lightsalmon1\"         \"lightsalmon2\"        \n#> [427] \"lightsalmon3\"         \"lightsalmon4\"         \"lightseagreen\"       \n#> [430] \"lightskyblue\"         \"lightskyblue1\"        \"lightskyblue2\"       \n#> [433] \"lightskyblue3\"        \"lightskyblue4\"        \"lightslateblue\"      \n#> [436] \"lightslategray\"       \"lightslategrey\"       \"lightsteelblue\"      \n#> [439] \"lightsteelblue1\"      \"lightsteelblue2\"      \"lightsteelblue3\"     \n#> [442] \"lightsteelblue4\"      \"lightyellow\"          \"lightyellow1\"        \n#> [445] \"lightyellow2\"         \"lightyellow3\"         \"lightyellow4\"        \n#> [448] \"limegreen\"            \"linen\"                \"magenta\"             \n#> [451] \"magenta1\"             \"magenta2\"             \"magenta3\"            \n#> [454] \"magenta4\"             \"maroon\"               \"maroon1\"             \n#> [457] \"maroon2\"              \"maroon3\"              \"maroon4\"             \n#> [460] \"mediumaquamarine\"     \"mediumblue\"           \"mediumorchid\"        \n#> [463] \"mediumorchid1\"        \"mediumorchid2\"        \"mediumorchid3\"       \n#> [466] \"mediumorchid4\"        \"mediumpurple\"         \"mediumpurple1\"       \n#> [469] \"mediumpurple2\"        \"mediumpurple3\"        \"mediumpurple4\"       \n#> [472] \"mediumseagreen\"       \"mediumslateblue\"      \"mediumspringgreen\"   \n#> [475] \"mediumturquoise\"      \"mediumvioletred\"      \"midnightblue\"        \n#> [478] \"mintcream\"            \"mistyrose\"            \"mistyrose1\"          \n#> [481] \"mistyrose2\"           \"mistyrose3\"           \"mistyrose4\"          \n#> [484] \"moccasin\"             \"navajowhite\"          \"navajowhite1\"        \n#> [487] \"navajowhite2\"         \"navajowhite3\"         \"navajowhite4\"        \n#> [490] \"navy\"                 \"navyblue\"             \"oldlace\"             \n#> [493] \"olivedrab\"            \"olivedrab1\"           \"olivedrab2\"          \n#> [496] \"olivedrab3\"           \"olivedrab4\"           \"orange\"              \n#> [499] \"orange1\"              \"orange2\"              \"orange3\"             \n#> [502] \"orange4\"              \"orangered\"            \"orangered1\"          \n#> [505] \"orangered2\"           \"orangered3\"           \"orangered4\"          \n#> [508] \"orchid\"               \"orchid1\"              \"orchid2\"             \n#> [511] \"orchid3\"              \"orchid4\"              \"palegoldenrod\"       \n#> [514] \"palegreen\"            \"palegreen1\"           \"palegreen2\"          \n#> [517] \"palegreen3\"           \"palegreen4\"           \"paleturquoise\"       \n#> [520] \"paleturquoise1\"       \"paleturquoise2\"       \"paleturquoise3\"      \n#> [523] \"paleturquoise4\"       \"palevioletred\"        \"palevioletred1\"      \n#> [526] \"palevioletred2\"       \"palevioletred3\"       \"palevioletred4\"      \n#> [529] \"papayawhip\"           \"peachpuff\"            \"peachpuff1\"          \n#> [532] \"peachpuff2\"           \"peachpuff3\"           \"peachpuff4\"          \n#> [535] \"peru\"                 \"pink\"                 \"pink1\"               \n#> [538] \"pink2\"                \"pink3\"                \"pink4\"               \n#> [541] \"plum\"                 \"plum1\"                \"plum2\"               \n#> [544] \"plum3\"                \"plum4\"                \"powderblue\"          \n#> [547] \"purple\"               \"purple1\"              \"purple2\"             \n#> [550] \"purple3\"              \"purple4\"              \"red\"                 \n#> [553] \"red1\"                 \"red2\"                 \"red3\"                \n#> [556] \"red4\"                 \"rosybrown\"            \"rosybrown1\"          \n#> [559] \"rosybrown2\"           \"rosybrown3\"           \"rosybrown4\"          \n#> [562] \"royalblue\"            \"royalblue1\"           \"royalblue2\"          \n#> [565] \"royalblue3\"           \"royalblue4\"           \"saddlebrown\"         \n#> [568] \"salmon\"               \"salmon1\"              \"salmon2\"             \n#> [571] \"salmon3\"              \"salmon4\"              \"sandybrown\"          \n#> [574] \"seagreen\"             \"seagreen1\"            \"seagreen2\"           \n#> [577] \"seagreen3\"            \"seagreen4\"            \"seashell\"            \n#> [580] \"seashell1\"            \"seashell2\"            \"seashell3\"           \n#> [583] \"seashell4\"            \"sienna\"               \"sienna1\"             \n#> [586] \"sienna2\"              \"sienna3\"              \"sienna4\"             \n#> [589] \"skyblue\"              \"skyblue1\"             \"skyblue2\"            \n#> [592] \"skyblue3\"             \"skyblue4\"             \"slateblue\"           \n#> [595] \"slateblue1\"           \"slateblue2\"           \"slateblue3\"          \n#> [598] \"slateblue4\"           \"slategray\"            \"slategray1\"          \n#> [601] \"slategray2\"           \"slategray3\"           \"slategray4\"          \n#> [604] \"slategrey\"            \"snow\"                 \"snow1\"               \n#> [607] \"snow2\"                \"snow3\"                \"snow4\"               \n#> [610] \"springgreen\"          \"springgreen1\"         \"springgreen2\"        \n#> [613] \"springgreen3\"         \"springgreen4\"         \"steelblue\"           \n#> [616] \"steelblue1\"           \"steelblue2\"           \"steelblue3\"          \n#> [619] \"steelblue4\"           \"tan\"                  \"tan1\"                \n#> [622] \"tan2\"                 \"tan3\"                 \"tan4\"                \n#> [625] \"thistle\"              \"thistle1\"             \"thistle2\"            \n#> [628] \"thistle3\"             \"thistle4\"             \"tomato\"              \n#> [631] \"tomato1\"              \"tomato2\"              \"tomato3\"             \n#> [634] \"tomato4\"              \"turquoise\"            \"turquoise1\"          \n#> [637] \"turquoise2\"           \"turquoise3\"           \"turquoise4\"          \n#> [640] \"violet\"               \"violetred\"            \"violetred1\"          \n#> [643] \"violetred2\"           \"violetred3\"           \"violetred4\"          \n#> [646] \"wheat\"                \"wheat1\"               \"wheat2\"              \n#> [649] \"wheat3\"               \"wheat4\"               \"whitesmoke\"          \n#> [652] \"yellow\"               \"yellow1\"              \"yellow2\"             \n#> [655] \"yellow3\"              \"yellow4\"              \"yellowgreen\"\n\n# Example\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue)) +\n  \n  geom_col(fill = \"slateblue\")\n\n\n\n\n\n\n\n# To RGB\ncol2rgb(\"slateblue\")\n\n#>       [,1]\n#> red    106\n#> green   90\n#> blue   205\n\ncol2rgb(\"#2C3E50\")\n\n#>       [,1]\n#> red     44\n#> green   62\n#> blue    80\n\n# To HEX (this function should be provided to a geom)\nrgb(44, 62, 80, maxColorValue = 255)\n\n#> [1] \"#2C3E50\"\n\n### Brewer. Comes with basic R.\n#Primarly for discrete data.\n\n# We can use those palletes by just calling their names (e.g. \"Blues\")\n# Display the colors\nRColorBrewer::display.brewer.all() \n\n\n\n\n\n\n\n# Get information\nRColorBrewer::brewer.pal.info\n\n\n\n  \n\n\n# Get the HEX codes\nRColorBrewer::brewer.pal(n = 8, name = \"Blues\")[1]\n\n#> [1] \"#F7FBFF\"\n\n# Example\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue)) +\n  \n  geom_col(fill = RColorBrewer::brewer.pal(n = 8, name = \"Blues\")[8])\n\n\n\n\n\n\n\n### Viridis\nviridisLite::viridis(n = 20)\n\n#>  [1] \"#440154FF\" \"#481568FF\" \"#482677FF\" \"#453781FF\" \"#3F4788FF\" \"#39558CFF\"\n#>  [7] \"#32648EFF\" \"#2D718EFF\" \"#287D8EFF\" \"#238A8DFF\" \"#1F968BFF\" \"#20A386FF\"\n#> [13] \"#29AF7FFF\" \"#3CBC75FF\" \"#56C667FF\" \"#74D055FF\" \"#94D840FF\" \"#B8DE29FF\"\n#> [19] \"#DCE318FF\" \"#FDE725FF\"\n\n# The last two characters indicate the transparency (e.g. FF makes it 100% transparent)\n\n# Example\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue)) +\n  \n  geom_col(fill = viridisLite::viridis(n = 20)[10])\n\n\n\n\n\n\n\nsales_by_year_category_1_tbl %>%\n  \n  # Put the aes color mapping here, to apply it to geom_line and geom_point\n  ggplot(aes(year, revenue, color = category_1)) +\n  \n  # Or you could do it locally in each geom \n  # (aes mapping only necessary if you map it to a column)\n  geom_line(size = 1) + # geom_line(aes(color = category_1))\n  geom_point(color = \"dodgerblue\", size = 5)\n\n\n\n\n\n\n\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue)) +\n  geom_col(aes(fill = category_1)) \n\n\n\n\n\n\n\n# You could use color = ... to color the outlines\n\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, size = revenue)) +\n  \n  # The local size overrides the global size\n  geom_line(aes(color = category_1), size = 1) + \n  geom_point()\n\n\n\n\n\n\n\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, color = category_1)) +\n  geom_line(color = \"black\") +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  \n  # Break out stacked plot\n  facet_wrap(~ category_1, ncol = 3, scales = \"free_y\") +\n  \n  expand_limits(y = 0)\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, fill = category_1)) +\n  # geom_col(position = \"stack\") # default\n  # geom_col(position = \"dodge\")\n  geom_col(position = position_dodge(width = 0.9), color = \"white\")\n\n\n\n\n\n\n\n# Stacked Area\n\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, fill = category_1)) +\n  geom_area(color = \"black\")\n\n\n\n\n\n\n\ng_facet_continuous <- sales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, color = revenue)) +\n  geom_line(size = 1) +\n  geom_point(size = 3) +\n  \n  facet_wrap(~ category_1, scales = \"free_y\") +\n  expand_limits(y = 0) +\n  \n  theme_minimal()\n\ng_facet_continuous\n\n\n\n\n\n\n\ng_facet_discrete <- sales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, color = category_1)) +\n  geom_line(size = 1) +\n  geom_point(size = 3) +\n  \n  facet_wrap(~ category_1, scales = \"free_y\") +\n  expand_limits(y = 0) +\n  \n  theme_minimal()\n\ng_facet_discrete\n\n\n\n\n\n\n\ng_area_discrete <- sales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, fill = category_1)) +\n  geom_area(color = \"black\") +\n  \n  theme_minimal()\n\ng_area_discrete\n\n\n\n\n\n\n\ng_area_discrete <- sales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, fill = category_1)) +\n  geom_area(color = \"black\") +\n  \n  theme_minimal()\n\ng_area_discrete\n\n\n\n\n\n\n\nRColorBrewer::display.brewer.all()\n\n\n\n\n\n\n\nRColorBrewer::brewer.pal.info\n\n\n\n  \n\n\nRColorBrewer::brewer.pal(n = 8, name = \"Blues\")\n\n#> [1] \"#F7FBFF\" \"#DEEBF7\" \"#C6DBEF\" \"#9ECAE1\" \"#6BAED6\" \"#4292C6\" \"#2171B5\"\n#> [8] \"#084594\"\n\ng_facet_discrete +\n  scale_color_brewer(palette = \"Set3\") +\n  theme_dark()\n\n\n\n\n\n\n\ng_facet_discrete +\n  scale_color_viridis_d(option = \"D\") +\n  theme_dark()\n\n\n\n\n\n\n\ng_area_discrete +\n  scale_fill_brewer(palette = \"Set3\")\n\n\n\n\n\n\n\ng_area_discrete +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\ng_facet_continuous +\n  scale_x_continuous(breaks = seq(2015, 2019, by = 2)) +\n  scale_y_continuous(labels = scales::dollar_format(scale = 1e-6, \n                                                    preix = \"\",\n                                                    suffix = \"M\"))\n\n\n\n\n\n\n\ng_facet_continuous +\n  \n  scale_x_continuous(breaks = seq(2011, 2015, by = 2)) +\n  scale_y_continuous(labels = scales::dollar_format(scale = 1e-6, \n                                                    suffix = \"M\")) +\n  \n  geom_smooth(method = \"lm\", se = FALSE) +\n  \n  scale_color_viridis_c() +\n  theme_dark() +\n  \n  labs(\n    title = \"Bike Sales\",\n    subtitle = \"Sales are trending up\",\n    caption = \"5-year sales trends\\ncomes from our ERP Database\",\n    x = \"Year\",\n    y = \"Revenue (M €)\",\n    color = \"Revenue\" # Legend text\n  )\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n#> Warning: The following aesthetics were dropped during statistical transformation: colour\n#> i This can happen when ggplot fails to infer the correct grouping structure in\n#>   the data.\n#> i Did you forget to specify a `group` aesthetic or to convert a numerical\n#>   variable into a factor?\n\n\n#> Warning: The following aesthetics were dropped during statistical transformation: colour\n#> i This can happen when ggplot fails to infer the correct grouping structure in\n#>   the data.\n#> i Did you forget to specify a `group` aesthetic or to convert a numerical\n#>   variable into a factor?\n#> The following aesthetics were dropped during statistical transformation: colour\n#> i This can happen when ggplot fails to infer the correct grouping structure in\n#>   the data.\n#> i Did you forget to specify a `group` aesthetic or to convert a numerical\n#>   variable into a factor?\n#> The following aesthetics were dropped during statistical transformation: colour\n#> i This can happen when ggplot fails to infer the correct grouping structure in\n#>   the data.\n#> i Did you forget to specify a `group` aesthetic or to convert a numerical\n#>   variable into a factor?\n#> The following aesthetics were dropped during statistical transformation: colour\n#> i This can happen when ggplot fails to infer the correct grouping structure in\n#>   the data.\n#> i Did you forget to specify a `group` aesthetic or to convert a numerical\n#>   variable into a factor?\n\n\n\n\n\n\n\n\ng_facet_continuous +\n  \n  theme_light() +\n  \n  theme(\n    axis.text.x = element_text(\n      angle = 45,\n      hjust = 1\n    ),\n    strip.background = element_rect(\n      color = \"black\",\n      fill  = \"cornflowerblue\",\n      size  = 1\n    ),\n    strip.text = element_text(\n      face  = \"bold\",\n      color = \"white\"\n    )\n  )\n\n#> Warning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\n#> i Please use the `linewidth` argument instead.\n\n\n\n\n\n\n\n\nsales_by_year_category_1_tbl %>%\n  \n  ggplot(aes(year, revenue, fill = category_1)) +\n  \n  geom_area(color = \"black\") +\n  \n  # Scales\n  scale_fill_brewer(palette = \"Blues\", direction = -1) +\n  scale_y_continuous(labels = scales::dollar_format(prefix = \"\", suffix = \" €\")) +\n  \n  # Labels\n  labs(\n    title = \"Sales Over Year by Category 1\",\n    subtitle = \"Sales Trending Upward\",\n    x = \"\",\n    y = \"Revenue (M €)\",\n    fill = \"2nd Category\",\n    caption = \"Bike sales trends look strong heading into 2020\"\n  ) +\n  \n  # Theme\n  theme_light() +\n  theme(\n    title = element_text(face = \"bold\", color = \"#08306B\")\n    \n  )\n\n\n\n\n\n\n\nlibrary(tidyverse)\nstarwars %>% \n  filter(!is.na(species)) %>%\n  count(species, sort = TRUE)\n\n\n\n  \n\n\n## # A tibble: 37 x 2\n##    species      n\n##    <chr>    <int>\n##  1 Human       35\n##  2 Droid        6\n##  3 Gungan       3\n##  4 Kaminoan     2\n##  5 Mirialan     2\n##  6 Twi'lek      2\n##  7 Wookiee      2\n##  8 Zabrak       2\n##  9 Aleena       1\n## 10 Besalisk     1\n## # … with 27 more rows\n\nstarwars %>%\n  filter(!is.na(species)) %>%\n  mutate(species = as_factor(species) %>% \n           fct_lump(n = 3)) %>%\n  count(species)\n\n\n\n  \n\n\n## # A tibble: 4 x 2\n##   species     n\n##   <fct>   <int>\n## 1 Human      35\n## 2 Droid       6\n## 3 Gungan      3\n## 4 Other      39\n\nf <- factor(c(\"a\", \"b\", \"c\", \"d\"), levels = c(\"b\", \"c\", \"d\", \"a\"))\nf\n\n#> [1] a b c d\n#> Levels: b c d a\n\n## a b c d\n## Levels: b c d a\n\nfct_reorder(f, c(2,3,1,4))\n\n#> [1] a b c d\n#> Levels: c a b d\n\n## a b c d\n## Levels: c a b d\n\nfct_relevel(f, \"a\")\n\n#> [1] a b c d\n#> Levels: a b c d\n\n## a b c d\n## Levels: a b c d\nfct_relevel(f, \"b\", \"a\")\n\n#> [1] a b c d\n#> Levels: b a c d\n\n## a b c d\n## Levels: b a c d\n\n# Move to the third position\nfct_relevel(f, \"a\", after = 2)\n\n#> [1] a b c d\n#> Levels: b c a d\n\n## a b c d\n## Levels: b c a d\n\n# Relevel to the end\nfct_relevel(f, \"a\", after = Inf)\n\n#> [1] a b c d\n#> Levels: b c d a\n\n## a b c d\n## Levels: b c d a\nfct_relevel(f, \"a\", after = 3)\n\n#> [1] a b c d\n#> Levels: b c d a\n\n## a b c d\n## Levels: b c d a\n\n# 1.0 Lollipop Chart: Top N Customers ----\nlibrary(tidyverse)\nlibrary(lubridate)\n\nbike_orderlines_tbl <- read_rds(\"../../bikes/02_wrangled_data/bike_orderlines.rds\")\n\nn <- 10\n# Data Manipulation\ntop_customers_tbl <- bike_orderlines_tbl %>%\n  \n  # Select relevant columns\n  select(bikeshop, total_price) %>%\n  \n  # Collapse the least frequent values into “other”\n  mutate(bikeshop = as_factor(bikeshop) %>% fct_lump(n = n, w = total_price)) %>%\n  \n  # Group and summarize\n  group_by(bikeshop) %>%\n  summarize(revenue = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # Reorder the column customer_city by revenue\n  mutate(bikeshop = bikeshop %>% fct_reorder(revenue)) %>%\n  # Place \"Other\" at the beginning\n  mutate(bikeshop = bikeshop %>% fct_relevel(\"Other\", after = 0)) %>%\n  # Sort by this column\n  arrange(desc(bikeshop)) %>%\n  \n  # Add Revenue Text\n  mutate(revenue_text = scales::dollar(revenue, \n                                       scale  = 1e-6, \n                                       prefix = \"\", \n                                       suffix = \"M €\")) %>%\n  \n  # Add Cumulative Percent\n  mutate(cum_pct = cumsum(revenue) / sum(revenue)) %>%\n  mutate(cum_pct_text = scales::percent(cum_pct)) %>%\n  \n  # Add Rank\n  mutate(rank = row_number()) %>%\n  mutate(rank = case_when(\n    rank == max(rank) ~ NA_integer_,\n    TRUE ~ rank\n  )) %>%\n  \n  # Add Label text\n  mutate(label_text = str_glue(\"Rank: {rank}\\nRev: {revenue_text}\\nCumPct: {cum_pct_text}\"))\n\n# Data Visualization\ntop_customers_tbl %>%\n  \n  # Canvas\n  ggplot(aes(revenue, bikeshop)) +\n  \n  # Geometries\n  geom_segment(aes(xend = 0, yend = bikeshop), \n               color = RColorBrewer::brewer.pal(n = 11, name = \"RdBu\")[11],\n               size  = 1) +\n  \n  geom_point(aes(size = revenue),\n             color = RColorBrewer::brewer.pal(n = 11, name = \"RdBu\")[11]) +\n  \n  geom_label(aes(label = label_text), \n             hjust = \"inward\",\n             size  = 3,\n             color = RColorBrewer::brewer.pal(n = 11, name = \"RdBu\")[11]) +\n  \n  # Formatting\n  scale_x_continuous(labels = scales::dollar_format(scale = 1e-6, \n                                                    prefix = \"\",\n                                                    suffix = \"M €\")) +\n  labs(\n    title = str_glue(\"Top {n} Customers\"),\n    subtitle = str_glue(\n      \"Start: {year(min(bike_orderlines_tbl$order_date))}\n               End:  {year(max(bike_orderlines_tbl$order_date))}\"),\n    x = \"Revenue (M €)\",\n    y = \"Customer\",\n    caption = str_glue(\"Top 6 customers contribute\n                           52% of purchasing power.\")\n  ) +\n  \n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\"),\n    plot.caption = element_text(face = \"bold.italic\")\n  )\n\n\n\n\n\n\n\n# Select columns and filter categories\npct_sales_by_customer_tbl <- bike_orderlines_tbl %>%\n  \n  select(bikeshop, category_1, category_2, quantity) %>%\n  filter(category_1 %in% c(\"Mountain\",\"Road\")) %>% \n  \n  # Group by category and summarize\n  group_by(bikeshop, category_1, category_2) %>%\n  summarise(total_qty = sum(quantity)) %>%\n  ungroup() %>%\n  \n  # Add missing groups (not necessarily mandatory, but we'd get holes in the plot)\n  # complete() creates NAs. We need to set those to 0.\n  complete(bikeshop, nesting(category_1, category_2)) %>% \n  mutate(across(total_qty, ~replace_na(., 0))) %>%  \n  \n  # Group by bikeshop and calculate revenue ratio\n  group_by(bikeshop) %>%\n  mutate(pct = total_qty / sum(total_qty)) %>%\n  ungroup() %>%\n  \n  # Reverse order of bikeshops\n  mutate(bikeshop = as.factor(bikeshop) %>% fct_rev()) %>%\n  # Just to verify\n  mutate(bikeshop_num = as.numeric(bikeshop))\n\n#> `summarise()` has grouped output by 'bikeshop', 'category_1'. You can override\n#> using the `.groups` argument.\n\n# Data Visualization\npct_sales_by_customer_tbl %>%\n  \n  ggplot(aes(category_2, bikeshop)) +\n  \n  # Geometries\n  geom_tile(aes(fill = pct)) +\n  geom_text(aes(label = scales::percent(pct, accuracy = 1L)), \n            size = 3) +\n  facet_wrap(~ category_1, scales = \"free_x\") +\n  \n  # Formatting\n  scale_fill_gradient(low = \"white\", high = \"#2C3E50\") +\n  labs(\n    title = \"Heatmap of Purchasing Habits\",\n    x = \"Bike Type (Category 2)\",\n    y = \"Customer\",\n    caption = str_glue(\n      \"Customers that prefer Road: \n        To be discussed ...\n        \n        Customers that prefer Mountain: \n        To be discussed ...\")\n  ) +\n  \n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\"),\n    plot.caption = element_text(face = \"bold.italic\")\n  )\n\n\n\n\n\n\n\n\n\n1 Challenge 4.1\n\nlibrary(data.table)\nlibrary(tidyverse) # loads ggplot2\nlibrary(lubridate)\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(scales)\nlibrary(maps)\n\n#> \n#> Attaching package: 'maps'\n\n\n#> The following object is masked from 'package:purrr':\n#> \n#>     map\n\noptions(repr.plot.width=50, repr.plot.height=3)\n\n# Challenge 1\n\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 306185 Columns: 67\n\n\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncovid_data_graph_tbl <- covid_data_tbl %>% # Read the covid data\n  filter(location == \"Europe\" | location == \"Germany\" | location == \"United Kingdom\" | location == \"France\" | location == \"Spain\" | location == \"United States\") %>% # Filter only the locations specified in the task\n  select(date,total_cases,location) %>% # Only date, total_cases and location are needed\n  filter(!is.na(total_cases)) %>% # Remove those dates where the total_cases number is not a number\n  filter(date < '2022-04-20') # Plot in task stops in may of 2022, so this data stops there as well\n\ncovid_data_dt <- as.data.table(covid_data_graph_tbl) # Convert tibble to data.frame\n\nlast_date_europe <- covid_data_dt[location == \"Europe\"][order(-date)][1]$date\nlast_date_USA <- covid_data_dt[location == \"United States\"][order(-date)][1]$date\n\naddMillions <- function(x, ...) #<== function will add \" %\" to any number, and allows for any additional formatting through \"format\".\n    format(paste0(x/(1e+06), \" M\"), ...)\n\ncovid_data_dt %>% ggplot(aes(x=date,y=total_cases),palette=\"Dark2\") + # plot total_cases over time\n  geom_line(aes(colour=location)) + # each location gets its own line\n  theme(legend.position = \"bottom\") + # position legend at the bottom\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%B '%y\") + # Change the x axis to a date axis with montly intervals and \"month 'year\" labels\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate the x-axis labels by 45 degrees so they don't collide with each other\n  scale_y_continuous(breaks = seq(0, 200000000, by = 50000000), labels = addMillions) + \n  labs( title = \"COVID-19 confirmed cases worldwide\", # Set plot title.\n        subtitle = \"As of 19/04/2022\", # Set plot subtitle.\n        y = \"Cumulative Cases\", # Set plot y-axis label.\n        colour=\"Continent / Country\") + # Set location/country legend title.\n  theme(axis.title.x=element_blank(), # Remove x axis label \n        text = element_text(size=10)) + # Increase text size\n\n  geom_label( # Display geom_label for europe and united states last data point\n    data=covid_data_dt %>% filter((location == \"Europe\" & date == last_date_europe) | (location == \"United States\" & date == last_date_USA)),\n    aes(label=total_cases),hjust=1,vjust=0.4\n  )\n\n\n\n\n\n\n\n\n#Challenge 4.2\n\n# Challenge 2\n\n# Get Case-Fatality rate (deaths/cases)\ncovid_data_graph_tbl <- covid_data_tbl %>% # Read the covid data.\n  filter(!is.na(total_cases) & !is.na(total_deaths) & !is.na(total_deaths_per_million)) %>% # Remove those dates where the total_cases number is not a number.\n  group_by(location) %>% summarise(total_cases = sum(total_cases),total_deaths = sum(total_deaths),total_deaths_per_million = sum(total_deaths_per_million)) %>% # Group by location (country) and sum up total_cases and total_deaths over all dates.\n  mutate(fatality_rate = (total_deaths/total_cases)) %>% # Add fatality_rate column to the tibble.\n                                                         # Can be exchanged for total_deaths_per_million to visualize mortality rate.\n  select(fatality_rate,location) %>%  # Only maintain fatality_rate and location\n  mutate(location = case_when( # Replace non matching location names\n    \n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n    \n  )) %>%\n  distinct()\n\ntotal_deaths_worldwide <- covid_data_tbl %>% filter(!is.na(total_deaths)) %>% group_by(location) %>% filter(row_number()==n()) %>% summarise(total_deaths) %>%\n                                        ungroup() %>% summarise(total_deaths = sum(total_deaths))\n\nlibrary(RColorBrewer)\nlibrary(maptools)\n\n#> Loading required package: sp\n\n\n#> Checking rgeos availability: FALSE\n#> Please note that 'maptools' will be retired by the end of 2023,\n#> plan transition at your earliest convenience;\n#> some functionality will be moved to 'sp'.\n#>      Note: when rgeos is not available, polygon geometry     computations in maptools depend on gpclib,\n#>      which has a restricted licence. It is disabled by default;\n#>      to enable gpclib, type gpclibPermit()\n\ncolour_breaks <- c(10, 20, 30)\ncolours <- c(\"darkblue\", \"lightblue\", \"yellow\")\n\nworld <- map_data(\"world\")\nggplot(covid_data_graph_tbl) + \n  geom_map(dat=world, map=world, \n           aes(map_id=region), fill=\"white\", color=\"black\") + \n  geom_map(map=world, \n           aes(map_id=location, fill=fatality_rate), color=\"black\") + \n  expand_limits(x = world$long, y = world$lat) +\n  labs( title = \"Confirmed COVID-19 fatality rate.\", # Set plot title.\n        subtitle = paste0(\"Around \",round(total_deaths_worldwide / 1e6, 1),\" Million confirmed COVID-19 deaths worldwide.\"), # Set plot subtitle.\n        caption = paste0(\"Date:\",format(Sys.Date(), format=\"%d/%m/%Y\")), # Set plot caption.\n        fill = \"Fatality rate\") + # Set plot legend caption.\n  theme(axis.title.x=element_blank(), # Remove x axis label. \n        axis.title.y=element_blank(), # Remove y axis label.\n        axis.ticks = element_blank(), # Remove axis ticks.\n        axis.text.x = element_blank(), # Remove x axis texts.\n        axis.text.y = element_blank(), # Remove y axis texts.\n        )"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "Tidyverse is a helpful collection of R packages by RStudios chief scientist. They are installed to do proper data science.\n\n\nPackages are installed via install.packages(\"packagename\") . We also need Rtools to be able to compile R packages.\n\n\n\nThe pipe operator %>% is used to concatenate function calls.\n\n\n\nTibbles are data frames but have a better behavior. The term tibble and data frame will be used interchangeably. It is a better data.frame realization. data frames can be typecasted to tibble.\n\n\n\nData can be imported from Excel sheets for example. The data is stored in the RAM of the computer. If there is to much data or the RAM is too small, that might cause issues.\n\n\ndiamonds2 <- readRDS(\"diamonds2.rds\")\ndiamonds2 %>% head(n = 5)\n\n\n\n\nData can be reshaped with tidyr. Afterwards, every observation is represented as one row, each variable is represented by one column and every data tables cell contains one value.\n\n\ndiamonds4 <- readRDS(\"diamonds4.rds\")\ndiamonds4 %>% \n  separate(col = dim,\n           into = c(\"x\", \"y\", \"z\"),\n           sep = \"/\",\n           convert = T)\nseperate() is used if one or more columns contain more than one value.\nunite() is used to paste multiple columns into one, the opposite of separate().\n\n\n\n\ndplyr is a grammar of data manipulation to solve the most common data manipulation challenges. This means for example the creation of new variables. There are different functions for different use cases which can be called.\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\ndiamonds %>% \n    filter(cut == 'Ideal' | cut == 'Premium', carat >= 0.23) %>% \n    head(5)\nfilter() in this context with this arguments shows every data line where carat is more or equal to 0.23.\ndiamonds %>% \n  arrange(cut, carat, desc(price))\narrange() is used for reordering the rows, in this case for descending price.\nrename() changes the name of a column."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own."
  }
]